# Enhanced BiLSTM-MultiHeadAttention Model for Aspect-Based Sentiment Analysis

## 1. 模型架构

### 1.1 整体架构
- **核心模型**: 增强型双向LSTM (`EnhancedBiLSTMModel`)
- **任务类型**: 18个独立的多分类任务 (每个方面对应一个4分类情感任务：未提及、负面、中性、正面)
- **主要技术**: 双向LSTM, 多头自注意力 (Multi-Head Attention), 门控特征融合 (Gated Feature Fusion), MLP分类器
- **词嵌入维度**: 300
- **LSTM隐藏层维度**: 128
- **LSTM层数**: 2
- **注意力头数**: 8
- **输出层**: 线性层输出 `num_aspects * num_sentiment_classes` 个原始分数 (logits)，不经过激活函数 (由`CrossEntropyLoss`处理)

### 1.2 主要组件
- **词嵌入层 (`nn.Embedding`)**: 将输入文本中的词索引转换为密集向量表示，使用`<PAD>`作为padding token。
- **嵌入层Dropout**: 防止过拟合。
- **双向LSTM层 (`nn.LSTM`)**: 2层堆叠，捕获文本序列的双向上下文依赖信息。
- **多头注意力层 (`Attention` x 8)**: 8个独立的自注意力头，并行计算上下文向量，允许模型关注文本的不同部分。
- **层归一化 (`nn.LayerNorm`)**: 应用于LSTM输出和多头注意力拼接输出之后，稳定训练过程。
- **门控特征融合**: 将多头注意力的输出进行拼接，通过一个门控机制（Sigmoid门 + 线性变换）和一个特征变换路径（线性变换 + GELU + Dropout）进行动态融合。
- **MLP分类器**: 多层感知机，包含线性层、GELU激活函数、层归一化和Dropout，用于进一步处理融合后的特征。
- **残差连接**: 在MLP输出和门控融合特征的一部分之间应用，可能有助于梯度流动。
- **输出层**: 包含线性层、层归一化、GELU和Dropout，最终通过一个线性层映射到 `18 * 4 = 72` 个输出分数，对应18个方面每个方面的4个情感类别。

## 2. 训练配置

### 2.1 数据处理
- **分词**: 使用 `jieba` 进行中文分词。
- **标签映射**: 将原始标签 (-2, -1, 0, 1) 映射为类别索引 (0, 1, 2, 3)。
- **序列处理**: 最大序列长度设置为128，进行填充 (`<PAD>`) 和截断。
- **词表构建**: 基于训练集（包含增强数据）构建词汇表，过滤词频低于2的词，使用`<UNK>`处理未登录词。
- **数据增强**: 使用简单的随机删除词策略扩充训练数据。

### 2.2 训练参数
- **批次大小 (`batch_size`)**: 32
- **优化器 (`optimizer`)**: `AdamW` (weight_decay=0.01)
- **损失函数 (`criterion`)**: `nn.CrossEntropyLoss` (适用于多分类任务)
- **训练轮数 (`num_epochs`)**: 10 (可配置)
- **学习率调度器 (`scheduler`)**: `OneCycleLR` (最大学习率2e-3, warmup比例0.1, 余弦退火)
- **梯度裁剪 (`grad_clip`)**: 1.0 (防止梯度爆炸)
- **早停机制 (`early_stopping`)**: 基于验证集平均F1分数，若连续3轮无提升则停止训练。
- **模型保存**: 保存验证集上F1分数最高的模型到 `analysis_output/best_model_on_f1.pth`。
- **随机种子**: 42 (用于CPU, Numpy, CUDA以保证可复现性)。
- **硬件加速**: 自动检测并使用CUDA (若可用)，DataLoader使用`pin_memory`和多进程(`num_workers`)加速。

## 3. 性能评估

### 3.1 评估指标 (多分类)
针对**每个方面**独立计算以下指标，然后计算所有方面的**平均值**作为整体性能参考：
- **准确率 (Accuracy)**: 衡量该方面所有情感类别预测正确的比例。
- **宏平均精确率 (Macro-Precision)**: 各情感类别精确率的算术平均值。
- **宏平均召回率 (Macro-Recall)**: 各情感类别召回率的算术平均值。
- **宏平均F1分数 (Macro-F1)**: 各情感类别F1分数的算术平均值 (这是早停和模型选择的主要依据)。
- **宏平均特异度 (Macro-Specificity)**: 各情感类别特异度 (真阴性率) 的算术平均值。
- **混淆矩阵 (Confusion Matrix)**: 每个方面生成一个 4x4 的混淆矩阵。

### 3.2 可视化分析 (保存于 `analysis_output` 目录)
- **`aspect_metrics_epoch_{epoch}.png`**: 每个epoch生成一张热力图，展示各方面指标（ACC, Macro-PPV, Macro-TPR, Macro-F1, Macro-TNR）的表现。
- **`training_and_f1_curves.png`**: 展示训练损失、验证损失以及验证集平均F1分数随训练轮数的变化曲线。
- **`average_{metric}_trend.png`**: 为每个主要指标（accuracy, precision, recall, f1, specificity）分别生成一张图，展示其在所有方面上的平均值随训练轮数的变化趋势。

### 3.3 细粒度评估
模型对18个不同的细粒度方面类别进行独立的情感4分类预测，包括：
- 位置相关：交通、市中心位置、易找程度
- 服务相关：排队、服务态度、停车、及时性
- 价格相关：价格水平、性价比、折扣
- 环境相关：装修、噪音、空间、卫生
- 食物相关：分量、口味、外观、推荐度

## 4. 模型优势

1. **上下文感知**: BiLSTM有效捕获文本的上下文信息。
2. **多视角关注**: 多头注意力机制允许模型从不同角度关注文本的关键部分。
3. **动态特征融合**: 门控机制使模型能自适应地融合来自不同注意力头的信息。
4. **先进的训练策略**: 使用AdamW优化器和OneCycleLR调度器，有助于模型更快更好地收敛。
5. **任务针对性**: 直接对每个方面进行多分类预测，更符合任务目标。
6. **正则化**: Dropout和AdamW的权重衰减有助于防止过拟合。

## 5. 改进方向

1. **预训练模型**: 考虑使用预训练的中文词向量或引入BERT等预训练语言模型作为Encoder，可能大幅提升性能。
2. **数据增强**: 探索更有效的数据增强方法，如回译、随机插入/交换等，并评估其影响。
3. **超参数调优**: 对模型维度、学习率、dropout率、优化器参数、OneCycleLR参数等进行系统性调优。
4. **处理类别不平衡**: 分析各方面情感类别的分布，如果存在严重不平衡，可考虑使用类别加权的损失函数或重采样技术。
5. **模型结构探索**: 尝试其他注意力变体（如Transformer Encoder层）或不同的序列建模方法。
6. **特征工程**: 考虑引入词性、依存句法等外部语言学特征。

## 6. 结论

当前模型是一个结合了双向LSTM、多头注意力、门控融合等技术的增强型序列模型。它被配置用于解决细粒度的方面情感分析任务，将每个方面视为一个独立的多分类问题（4种情感类别）。模型采用了AdamW优化器、OneCycleLR学习率策略、梯度裁剪和早停机制进行训练。评估体系关注每个方面的多分类性能指标（准确率、宏平均P/R/F1/Specificity），并提供了丰富的可视化结果。虽然当前模型已具备一定复杂性，但仍有通过引入预训练模型、改进数据增强、超参数调优等方式进一步提升性能的空间。